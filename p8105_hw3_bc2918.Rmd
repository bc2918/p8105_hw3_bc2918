
---
title: "Homework 3"
author: "Beibei Cao"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document

---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(arsenal)
library(readr)
library(patchwork)
library(p8105.datasets)

knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%",
	warning = FALSE,
	message = FALSE
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs. ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

## Problem 2

This problem uses five weeks of accelerometer data collected on a 63 year-old male with BMI 25, who was admitted to the Advanced Cardiac Care Center of Columbia University Medical Center and diagnosed with congestive heart failure (CHF).

Load, tidy, and otherwise wrangle the accelerometer data.
```{r}
# load the accel csv, transform the df from wide to long format
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
   cols = starts_with("activity_"),
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  # encode data with reasonable variable classes, make the weekday ordered, add the weekend column
  mutate(
    week = as.integer(week),
    day_id = as.integer(day_id),
    day = as.factor(day),
    day = ordered(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
    minute = as.integer(minute),
    weekend = if_else(day %in% c("Saturday", "Sunday"), TRUE, FALSE)
  ) %>% 
  # sort by week, day and minute
  arrange(week, day, minute)
```

```{r}
# preview the df
accel_df
```


The `accel_df` contains ``r nrow(accel_df)`` observations of ``r ncol(accel_df)`` variables related to accelerometer data collected on the male. The `week` is an integer variable indicating the nth week of the observation  (``r min(accel_df$week)` - `r max(accel_df$week)``); the `day_id` is an integer variable indicating a unique id of the specific day from ``r min(accel_df$day_id)`` to ``r max(accel_df$day_id)``; the `day` is an ordered factor variable indicate the day of the week; the `activity_count` is a double numeric variable represents the activity counts in each minute ranging from ``r min(accel_df$activity_count)`` to ``r max(accel_df$activity_count)``; the `weekend` is a logical variable indicating whether the day is a weekend or not.

Using the tidied dataset, aggregate accross minutes to create a total activity variable for each day, and create a table showing these totals. 

```{r}
# group by week and day
accel_df %>% 
  group_by(week, day) %>% 
  # add up activity count of each day
  summarise(day_sum = sum(activity_count)) %>% 
  # format the table into wide 
  pivot_wider(
    names_from = day,
    values_from = day_sum
  ) %>% 
  knitr::kable(align = "crrrrrrr")
```

Visualize the trends of the total activity in the five week on each day.

```{r}
theme_set(theme_minimal() + theme(legend.position = "right"))
# visualize the trends of the total activity variable
 accel_df %>% 
  group_by(week, day) %>% 
  # add up activity count of each day
  summarise(day_sum = sum(activity_count)) %>% 
  ggplot(aes(x = day ,y = day_sum, group = week, color = week)) + 
  geom_line() + 
  geom_point() +
  labs(
    title = "Total Activity Counts of Each Day in the Week",
    x = "Day of the Week",
    y = "Day Activity Counts",
    color = "Day of the week",
    caption = "Accelerometer data collected from a 63 year-old male with BMI 25."
    ) 
  
```

No significant trend could be observed except for that in week 4 and week 5 very little activity was observed on Saturday and not many activities on Sunday. 

Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week. 

```{r}
accel_df %>% 
  group_by(day, minute) %>% 
  # add up activity count of each day in the week across five weeks
  summarise(weekday_sum = sum(activity_count)) %>% 
  # plot with activity count of each day across five weeks against day time
  ggplot(aes(x = minute, y = weekday_sum, color = day)) + 
  geom_point(alpha = 0.3, size = 0.5) +
  geom_smooth(size = 0.5, se = FALSE) +
  labs(
    title = "24-Hour Activity Time Courses for Each Day",
    x = "24-hour of the Day (h)",
    y = "Activity Level",
    color = "Day of a Week",
    caption = "Accelerometer data collected from a 63 year-old male with BMI 25."
    ) +
  scale_x_continuous(
    breaks = c(seq(0, 1440, by = 60)),
    labels = c(seq(0, 24, by = 1))
    ) 

```

Generally, low activities levels could be observed from `23 p.m.` to `5 a.m.`, when it was probably that the man was asleep. The activity levels peaked a little bit around the middle of each day (especially Sunday) and the end of each day (especially Friday), indicating there might be regular activities around that time.

## Problem 3

This problem uses the NY NOAA weather data. 

Load the data.

```{r}
data("ny_noaa")
```

Some data cleaning.

```{r}
tidy_naoo_df = 
  ny_noaa %>% 
  # create separate variables for year, month, and day
  separate(date, c("year", "month", "day")) %>%
  # recode column types and make variable prcp, tmin and tmax to have mm and degree C as units.
  mutate(
    year = as.integer(year),
    month = month.name[as.numeric(month)],
    day = as.integer(day),
    prcp = as.numeric(prcp) / 10,
    tmin = as.numeric(tmin) / 10,
    tmax = as.numeric(tmax) / 10
    )
```

Check the most commonly observed values in snowfall.
```{r}
# count the occurrence of snow records and rank
tidy_naoo_df %>% 
  drop_na(snow) %>% 
  group_by(snow) %>% 
	count(snow) %>% 
  ungroup() %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 6) %>% 
  arrange(rank) %>% 
  knitr::kable(align = "ccc") 
```

The most commonly observed value is `0`, which indicates that for the most of the time there is no snow.

Make a two-panel plot showing the average max temperature in January and in July in each station across years. 

```{r}
# subset data and calculate average max temperature for each station in the January and July
tidy_naoo_df %>% 
  filter(month %in% c("January", "July")) %>% 
  group_by(id, year, month) %>% 
  summarise(mean_tmax = mean(tmax)) %>% 
  # Make a two-panel plot showing the average max temperature in January and in July in each station across years
  ggplot(aes(x = year, y = mean_tmax, color = id)) + 
  geom_point(alpha = 0.4, size = 0.7) +
  labs(
    title = "New York State Average Max Temperature in January and July",
    x = "Year",
    y = "Average Max Temperature (°C)",
    caption = "Weather data accessed from the NOAA National Climatic Data Center, http://doi.org/10.7289/V5D21VHZ."
  ) +
  scale_x_continuous(
    breaks = c(seq(1980, 2010, by = 5)),
    labels = c(seq(1980, 2010, by = 5))
  ) +
  theme(legend.position = "none") + 
  facet_grid(. ~ month)
```

The average max temperature are well distributed around `0°C (~ -10°C to 10°C)` and `27°C (~ 20°C to 35°C)` in January and July respectively across the years. Few outliers could be observed. 

Plot `tmax` vs. `tmin` for the full dataset.
```{r}
# plot with geom_hex(), x = tmin, y = tmax, the color indicates level of counts (density of points)
tmax_tmin_plot = 
  tidy_naoo_df %>%
  drop_na() %>% 
  ggplot(aes(x = tmin, y = tmax)) + 
  geom_hex() +
  labs(
    title = "Max vs. Min Temperature",
    x = "Max Temperature (°C)",
    y = "Min Temperature (°C)"
  ) +
  theme(legend.position = "right")
```

Make a plot showing the distribution of snowfall values greater than `0` and less than `100` separately by year.

```{r }
# use violin plot to show the distribution of snowfall in each year, mean indicated
snow_plot = 
  tidy_naoo_df %>%
  drop_na() %>% 
  filter(snow > 0 & snow < 100) %>%
  ggplot(aes(x = year, y = snow, group = year, fill = year, color = year)) +
  geom_violin() +
  stat_summary(shape = 23, size = 0.2, color = "black") +
    labs(
    title = "Snowfall (0 - 100 mm)",
    x = "Year",
    y = "Snowfall (mm)",
    caption = "Weather data accessed from the NOAA National Climatic Data Center, http://doi.org/10.7289/V5D21VHZ."
  ) +
  scale_x_continuous(
    breaks = c(seq(1980, 2010, by = 5)),
    labels = c(seq(1980, 2010, by = 5))
  ) +
  theme(legend.position = "none")

```

Show two plots with Patchwork.
```{r}
tmax_tmin_plot + snow_plot 
```

Check missing values for each column.
```{r}
# sum the na in each variable
tidy_naoo_df %>% 
  is.na() %>% 
  colSums() 
```


The `tidy_naoo_df` contains ``r nrow(tidy_naoo_df)`` observations of ``r ncol(tidy_naoo_df)`` variables related to New York state weather data accessed from the NOAA National Climatic Data Center. The variable `id` contains id of ``r length(unique(tidy_naoo_df$id))`` stations that the data was collected from. The variable `year` (1981 - 2010), `month` and `day` contains the date information. The variable `prcp` is a double numeric variable containing data of precipitation with unit `mm`. The variable `snow` and `snwd` are integer variables containing data of snowfall and snow depth with units `mm`. The variable `tmax` and `tmin` are double numeric variables containing data of max and min temperatures with unit `°C`. The number of missing values for each variable are shown above. The `prcp`, `snow` and `snwd` variable have few missing values compared with the data size. The `tmax` and `tmin` variable have relatively more missing values however. These values are ignored when plotting.  

From the first plot in the two-panel plot, it could be observed that the tmax vs. tmin data points are generally distributed along a linear function with positive gradient and negative y-axis intercept, with a concentration between `(-20°C, -10°C)` and `(20°C, 30°C)`. The second plot indicated that the distribution of snowfall amount in each year did not vary much and their mean values were pretty consistent around `~30 mm`.













